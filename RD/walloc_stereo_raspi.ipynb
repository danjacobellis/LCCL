{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac795b8-44b5-4878-826c-7e9df752d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://hf.co/danjacobellis/walloc/resolve/main/Stereo_Li_27c_test2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ec9f03-99de-43f2-9276-3aebd3902c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:                    aarch64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          4\n",
      "On-line CPU(s) list:             0-3\n",
      "Thread(s) per core:              1\n",
      "Core(s) per socket:              4\n",
      "Socket(s):                       1\n",
      "Vendor ID:                       ARM\n",
      "Model:                           3\n",
      "Model name:                      Cortex-A72\n",
      "Stepping:                        r0p3\n",
      "CPU max MHz:                     1500.0000\n",
      "CPU min MHz:                     600.0000\n",
      "BogoMIPS:                        108.00\n",
      "Vulnerability Itlb multihit:     Not affected\n",
      "Vulnerability L1tf:              Not affected\n",
      "Vulnerability Mds:               Not affected\n",
      "Vulnerability Meltdown:          Not affected\n",
      "Vulnerability Spec store bypass: Vulnerable\n",
      "Vulnerability Spectre v1:        Mitigation; __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Vulnerable\n",
      "Vulnerability Srbds:             Not affected\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "Flags:                           fp asimd evtstrm crc32 cpuid\n"
     ]
    }
   ],
   "source": [
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from IPython.display import Audio\n",
    "from torchvision.transforms import ToPILImage, PILToTensor\n",
    "from datasets import load_dataset, Image\n",
    "from walloc import walloc\n",
    "class Config: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389e035a-effe-4599-807b-96c213e5a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/.local/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Stereo_Li_27c_test2.pth\",map_location=\"cpu\",weights_only=False)\n",
    "codec_config = checkpoint['config']\n",
    "codec = walloc.Codec1D(\n",
    "    channels = codec_config.channels,\n",
    "    J = codec_config.J,\n",
    "    Ne = codec_config.Ne,\n",
    "    Nd = codec_config.Nd,\n",
    "    latent_dim = codec_config.latent_dim,\n",
    "    latent_bits = codec_config.latent_bits,\n",
    "    lightweight_encode = codec_config.lightweight_encode,\n",
    "    post_filter = codec_config.post_filter\n",
    ")\n",
    "codec.load_state_dict(checkpoint['model_state_dict'])\n",
    "codec.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f156141c-9fed-4893-a143-02abbe802822",
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSDB = load_dataset(\"danjacobellis/musdb_segments_val\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a63a7e-c0a6-4bfe-846e-cd60a53a41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B,C,L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        audio = torch.nn.functional.pad(audio, (0, padding_size), mode='constant', value=0)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ed7b5ec-3124-470f-86b4-359c2389e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walloc_compress_cpu(sample):\n",
    "    with torch.no_grad():\n",
    "        x, fs = torchaudio.load(sample['audio_mix']['bytes'],normalize=False)\n",
    "        x = x.to(torch.float)\n",
    "        x = x - x.mean()\n",
    "        max_abs = x.abs().max()\n",
    "        x = x / (max_abs + 1e-8)\n",
    "        x = x/2\n",
    "        \n",
    "        L = x.shape[-1]\n",
    "        x_padded = pad(x.unsqueeze(0), 2**16).to(device)\n",
    "        t0 = time.time()\n",
    "        X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "        Y = codec.encoder(X)\n",
    "        ℓ = Y.shape[-1]\n",
    "        Y = pad(Y,256)\n",
    "        Y = rearrange(Y, 'b c (w h) -> b c w h', h=256).to(\"cpu\")\n",
    "        webp = walloc.latent_to_pil(Y,codec.latent_bits,3)[0]\n",
    "        buff = io.BytesIO()\n",
    "        webp.save(buff, format='WEBP', lossless=True)\n",
    "        webp_bytes = buff.getbuffer()\n",
    "        encode_time = time.time() - t0\n",
    "    \n",
    "        t0 = time.time()\n",
    "        Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "        X_hat = codec.decoder(rearrange(Y.to(device), 'b c h w -> b c (h w)')[:,:,:ℓ])\n",
    "        x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "        x_hat = codec.post(x_hat)\n",
    "        x_hat = codec.clamp(x_hat[0,:,:L])\n",
    "        decode_time = time.time() - t0\n",
    "        \n",
    "    return {\n",
    "        'cpu_encode_time': encode_time,\n",
    "        'cpu_decode_time': decode_time,\n",
    "        'shape': x.shape,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5ddb0a9-70c7-46c4-b8bd-83aa7eb73268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6cb52df723468f8a3ec8b0b4b457f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "codec = codec.to(device)\n",
    "cpu = MUSDB.select(range(8)).map(walloc_compress_cpu, writer_batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5904369-e0e7-4359-9ae4-78beaa8c8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload = cpu.remove_columns(['audio_mix', 'path_vocal', 'path_bass', 'path_drums', 'path_other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "935864d0-9ab8-4abe-a8f1-f5ca79943fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode:  2.708 megasamples per second\n"
     ]
    }
   ],
   "source": [
    "enc_samp_per_sec = np.prod(upload[0]['shape'])/np.array(upload['cpu_encode_time'])\n",
    "print(f\"Encode: {np.mean(enc_samp_per_sec)/1e6 : .5g} megasamples per second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e98d8ce-53bb-4d00-b2b2-cc9240b0926c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode:  5.6591 seconds per megasample\n"
     ]
    }
   ],
   "source": [
    "dec_sec_per_samp = np.array(upload['cpu_decode_time'])/np.prod(upload[0]['shape'])\n",
    "print(f\"Decode: {1e6*np.mean(dec_sec_per_samp) : .5g} seconds per megasample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "598917b0-d1c4-43ab-97a3-ab46cbdd757f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "934af7dacc904f82b24c38eb0874ce6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5ca63b54f64b09a0404a6839419483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/danjacobellis/MUSDB_walloc_20x_raspi/commit/6409553d099de697ee5f61d6c85fad1ab2457988', commit_message='Upload dataset', commit_description='', oid='6409553d099de697ee5f61d6c85fad1ab2457988', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload.push_to_hub(\"danjacobellis/MUSDB_walloc_20x_raspi\",split='validation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
