{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3be548-2f74-488e-a783-20097670ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://hf.co/danjacobellis/walloc/resolve/main/Stereo_Li_48c_J8_nf8_v1.0.2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ec9f03-99de-43f2-9276-3aebd3902c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name --format=csv,noheader | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from IPython.display import Audio\n",
    "from torchvision.transforms import ToPILImage, PILToTensor\n",
    "from datasets import load_dataset, Image\n",
    "from walloc import walloc\n",
    "from spauq.core.metrics import spauq_eval\n",
    "import cdpam\n",
    "class Config: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389e035a-effe-4599-807b-96c213e5a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Stereo_Li_48c_J8_nf8_v1.0.2.pth\",map_location=\"cpu\",weights_only=False)\n",
    "codec_config = checkpoint['config']\n",
    "codec = walloc.Codec1D(\n",
    "    channels = codec_config.channels,\n",
    "    J = codec_config.J,\n",
    "    Ne = codec_config.Ne,\n",
    "    Nd = codec_config.Nd,\n",
    "    latent_dim = codec_config.latent_dim,\n",
    "    latent_bits = codec_config.latent_bits,\n",
    "    lightweight_encode = codec_config.lightweight_encode,\n",
    "    post_filter = codec_config.post_filter\n",
    ")\n",
    "codec.load_state_dict(checkpoint['model_state_dict'])\n",
    "codec.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc6e03e-ffcc-443f-be69-f6f75ba737e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/cdpam/cdpam.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(modfolder,map_location=\"cpu\")['state']\n"
     ]
    }
   ],
   "source": [
    "cdpam_loss = cdpam.CDPAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f156141c-9fed-4893-a143-02abbe802822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9bed8934994835ab989193c3b90f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1048426749344a7b6450c9f4baf9155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8feb3cf675d547dab6409e38cda8d4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0d762275b74cca81ee5b18bd1817a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MUSDB = load_dataset(\"danjacobellis/musdb18HQ\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19a63a7e-c0a6-4bfe-846e-cd60a53a41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B,C,L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        audio = torch.nn.functional.pad(audio, (0, padding_size), mode='constant', value=0)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c53fec1-ada4-42c6-a4c7-592046255e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 44100*180\n",
    "def walloc_compress(sample):\n",
    "    with torch.no_grad():\n",
    "        x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "        x = x[:,:max_duration]\n",
    "        L = x.shape[-1]\n",
    "        x_padded = pad(x.unsqueeze(0), 2**16).to(device)\n",
    "        t0 = time.time()\n",
    "        X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "        Y = codec.encoder(X)\n",
    "        ℓ = Y.shape[-1]\n",
    "        Y = pad(Y,256)\n",
    "        Y = rearrange(Y, 'b c (w h) -> b c w h', h=256).to(\"cpu\")\n",
    "        webp = walloc.latent_to_pil(Y,codec.latent_bits,3)[0]\n",
    "        buff = io.BytesIO()\n",
    "        webp.save(buff, format='WEBP', lossless=True)\n",
    "        webp_bytes = buff.getbuffer()\n",
    "        encode_time = time.time() - t0\n",
    "    \n",
    "        t0 = time.time()\n",
    "        Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "        X_hat = codec.decoder(rearrange(Y.to(device), 'b c h w -> b c (h w)')[:,:,:ℓ])\n",
    "        x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "        x_hat = codec.post(x_hat)\n",
    "        x_hat = x_hat[0,:,:L].clamp(-1., 1.)\n",
    "        decode_time = time.time() - t0\n",
    "    \n",
    "        bps = 8*len(webp_bytes)/(x.numel())\n",
    "        PSNR = 20*np.log10(2) - 10*np.log10(torch.nn.functional.mse_loss(x,x_hat.to(\"cpu\")))\n",
    "        SDR = spauq_eval(x,x_hat.to(\"cpu\"),fs=fs)\n",
    "        SSDR = SDR['SSR']\n",
    "        SRDR = SDR['SRR']\n",
    "        cdpam = cdpam_loss.forward(x.to(device),x_hat).mean().item()\n",
    "        \n",
    "    return {\n",
    "        'compressed': webp_bytes,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'bps': bps,\n",
    "        'L': L,\n",
    "        'PSNR': PSNR,\n",
    "        'SSDR': SSDR,\n",
    "        'SRDR': SRDR,\n",
    "        'CDPAM': cdpam\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07a4d392-f9b7-4d92-b656-a33ecffdf2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0b2771827845f9a7b72f38741c1cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "codec = codec.to(device)\n",
    "gpu = MUSDB.map(\n",
    "    walloc_compress,\n",
    "    writer_batch_size=16,\n",
    ")\n",
    "gpu = gpu.cast_column('compressed',Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed7b5ec-3124-470f-86b4-359c2389e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walloc_compress_cpu(sample):\n",
    "    with torch.no_grad():\n",
    "        x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "        x = x[:,:max_duration]\n",
    "        L = x.shape[-1]\n",
    "        x_padded = pad(x.unsqueeze(0), 2**16).to(device)\n",
    "        t0 = time.time()\n",
    "        X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "        Y = codec.encoder(X)\n",
    "        ℓ = Y.shape[-1]\n",
    "        Y = pad(Y,256)\n",
    "        Y = rearrange(Y, 'b c (w h) -> b c w h', h=256).to(\"cpu\")\n",
    "        webp = walloc.latent_to_pil(Y,codec.latent_bits,3)[0]\n",
    "        buff = io.BytesIO()\n",
    "        webp.save(buff, format='WEBP', lossless=True)\n",
    "        webp_bytes = buff.getbuffer()\n",
    "        encode_time = time.time() - t0\n",
    "    \n",
    "        t0 = time.time()\n",
    "        Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "        X_hat = codec.decoder(rearrange(Y.to(device), 'b c h w -> b c (h w)')[:,:,:ℓ])\n",
    "        x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "        x_hat = codec.post(x_hat)\n",
    "        x_hat = x_hat[0,:,:L].clamp(-1., 1.)\n",
    "        decode_time = time.time() - t0\n",
    "        \n",
    "    return {\n",
    "        'cpu_encode_time': encode_time,\n",
    "        'cpu_decode_time': decode_time,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5ddb0a9-70c7-46c4-b8bd-83aa7eb73268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a9344b100d41a3b5a6c98d1eee6a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "codec = codec.to(device)\n",
    "cpu = MUSDB.map(walloc_compress_cpu, writer_batch_size=16)\n",
    "combined = gpu.add_column('cpu_encode_time',cpu['cpu_encode_time'])\n",
    "combined = combined.add_column('cpu_decode_time',cpu['cpu_decode_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e77d2fd0-f5b5-45b8-a386-65db975d376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "    'bps',\n",
    "    'PSNR',\n",
    "    'SSDR',\n",
    "    'SRDR',\n",
    "    'CDPAM',\n",
    "    'cpu_encode_time',\n",
    "    'cpu_decode_time',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1baaf00-9378-40ab-95d0-ef8f3e1d9245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_time: 0.05361144924163818\n",
      "decode_time: 0.008066473007202148\n",
      "bps: 0.2701805950207829\n",
      "PSNR: 33.14359369659424\n",
      "SSDR: 27.539516615683134\n",
      "SRDR: 7.411177765554664\n",
      "CDPAM: 0.00010840650893260318\n",
      "cpu_encode_time: 0.37957072257995605\n",
      "cpu_decode_time: 2.0746664352416992\n"
     ]
    }
   ],
   "source": [
    "for metric in metrics:\n",
    "    μ = np.mean(combined[metric])\n",
    "    print(f\"{metric}: {μ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598917b0-d1c4-43ab-97a3-ab46cbdd757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.push_to_hub(\"danjacobellis/Stereo_Li_48c_J8_nf8\",split='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa3f54-5f05-4607-b805-14a4e3fbc2c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4253a3a3-40d1-49fd-8f04-190dc481423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = 1048064\n",
    "# sample = MUSDB[5]\n",
    "# x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "# x = x[:,:L]\n",
    "# codec = codec.to(\"cuda\")\n",
    "# x = x.to(\"cuda\").unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     X = codec.wavelet_analysis(x,codec.J)\n",
    "#     Y = codec.encoder(X)\n",
    "#     Z = codec.decoder(Y)\n",
    "#     z = codec.wavelet_synthesis(Z,codec.J)\n",
    "#     z = codec.post(z)\n",
    "# x = x.to(\"cpu\")[0]\n",
    "# z = z.to(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80f71af-4b52-4afc-8ad6-d03af3828982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(x.numpy(),rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f56389a-c617-4510-8d0b-d08b4e96ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(z.numpy(),rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e614a2-25ec-413a-b664-cb5a74a0e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start, end = 56500, 57000\n",
    "# plt.figure(figsize=(8, 4), dpi=180)\n",
    "# plt.plot(x[0, start:end], alpha=0.5, c='b', label='Ch.1 (Uncompressed)')\n",
    "# plt.plot(z[0, start:end], alpha=0.5, c='g', label='Ch.1 (WaLLoC)')\n",
    "# plt.plot(x[1, start:end], alpha=0.5, c='r', label='Ch.2 (Uncompressed)')\n",
    "# plt.plot(z[1, start:end], alpha=0.5, c='purple', label='Ch.2 (WaLLoC)')\n",
    "\n",
    "# plt.ylim([-1,0.6])\n",
    "# plt.legend(loc='lower center')\n",
    "# plt.box(False)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# # plt.savefig(\"test.svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
