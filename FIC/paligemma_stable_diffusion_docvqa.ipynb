{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01bfb329-be53-457a-a199-5c0492274190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "from datasets import load_dataset\n",
    "from datasets import Image as HFImage\n",
    "from anls_star import anls_score\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "from diffusers.models.autoencoders import AutoencoderKL\n",
    "from torchvision.transforms import ToPILImage, PILToTensor\n",
    "from walloc import walloc\n",
    "class Config: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f76897-6029-435d-b45b-a46bd6b707d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd3_compress(sample):\n",
    "    with torch.no_grad():\n",
    "        img = sample['image'].resize((896,896),resample=Image.Resampling.LANCZOS).convert(\"RGB\")\n",
    "        x = PILToTensor()(img).to(torch.float)\n",
    "        x = (x/255 - 0.5).unsqueeze(0).to(device)\n",
    "        H, W = x.size(2), x.size(3)\n",
    "        x_padded = walloc.pad(x,p=8)\n",
    "        \n",
    "        # X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "        # Y = codec.encoder(X)\n",
    "        Y = codec.encode(x).latent_dist.mode().to(torch.float16).to(\"cpu\")\n",
    "        \n",
    "        # X_hat = codec.decoder(Y)\n",
    "        # x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "        x_hat = codec.decode(Y.to(device).to(torch.float)).sample\n",
    "\n",
    "        # x_hat = codec.clamp(x_hat)\n",
    "        x_hat = x_hat.clamp(-0.5,0.5)\n",
    "        \n",
    "        x_hat = walloc.crop(x_hat, (H,W))\n",
    "        rec = ToPILImage()(x_hat[0] + 0.5)\n",
    "        buff = io.BytesIO()\n",
    "        rec.save(buff, format='WEBP', lossless=True)\n",
    "        rec_webp_bytes = buff.getbuffer()   \n",
    "    return {\n",
    "        'image': rec_webp_bytes,\n",
    "        'question': sample['question'],\n",
    "        'questionId': sample['questionId'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca049dd2-d28f-448f-85dd-67dea98fe281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636703f102fd4775818e5ee6832bf5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0fa8769eaa40b7b4464753428c7a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/57 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = load_dataset(\"danjacobellis/docvqa\",split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0d30da-5794-433c-873d-517008406d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "codec = AutoencoderKL.from_pretrained(\"stabilityai/stable-diffusion-3-medium-diffusers\", subfolder='vae')\n",
    "codec.eval();\n",
    "codec = codec.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6bf5db-92a7-48f7-a7fe-04481bbd931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_ds = ds.map(sd3_compress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10f235d0-4e25-4613-8228-39d14af10f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6e7e62af1a4b2fb4b0b8b2e99c4e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"google/paligemma-3b-ft-docvqa-896\"\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cuda\",\n",
    "    revision=\"bfloat16\",\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6efb339-94bb-4e26-b8a9-b753cc270ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(item):\n",
    "    prompt = item['question']\n",
    "    image = item['image']\n",
    "    model_inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(model.device)\n",
    "    input_len = model_inputs[\"input_ids\"].shape[-1]\n",
    "    with torch.inference_mode():\n",
    "        generation = model.generate(**model_inputs, max_new_tokens=100, do_sample=False)\n",
    "        generation = generation[0][input_len:]\n",
    "        pred = processor.decode(generation, skip_special_tokens=True)\n",
    "    score, _ = anls_score(item['answer'], pred, return_gt=True)\n",
    "    return score, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf90fe72-b4cd-4c64-99f0-9296c2b0b06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='521' class='' max='5188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      10.04% [521/5188 02:36&lt;23:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "preds = []\n",
    "qid = []\n",
    "for item in progress_bar(sd_ds):\n",
    "    score, pred = compute_score(item)\n",
    "    scores.append(score)\n",
    "    preds.append(pred)\n",
    "    qid.append(item['questionId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc91b0-af89-497a-a65b-dca473bb422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_ds = sd_ds.add_column('preds_12x', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34982e6b-e542-4e0e-b348-fee367ff6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_ds.push_to_hub(\"danjacobellis/docvqa_stable_diffusion_3\",split='test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
