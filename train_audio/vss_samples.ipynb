{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b575600f-e76e-4098-8b05-86bbee490c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchvision\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f258bd-068c-455b-b854-631de4a5e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "class Config: pass\n",
    "config = Config()\n",
    "config.batch_size = 16\n",
    "config.num_workers = 12\n",
    "config.grad_accum_steps = 1\n",
    "config.plot_update = 64\n",
    "config.patience = 64\n",
    "config.min_lr = 1e-7\n",
    "config.max_lr = 3e-5\n",
    "config.warmup_steps = 5000\n",
    "config.weight_decay = 0.\n",
    "config.epochs = 2000\n",
    "\n",
    "config.length_samples = 2**20\n",
    "config.channels = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "caca760e-9293-4509-b159-e3fc78268bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"danjacobellis/musdb18hq_vss\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "645876ab-19e6-4653-a013-f2eb71b24a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = config.length_samples\n",
    "C = config.channels\n",
    "crop = torchvision.transforms.RandomCrop((2,L))\n",
    "def collate_fn(batch):\n",
    "    B = len(batch)\n",
    "    x = torch.zeros( (B, C, 2, L), dtype=torch.float32)\n",
    "    i_sample = 0\n",
    "    for i_sample, sample in enumerate(batch):\n",
    "        audio_mix, fs = torchaudio.load(sample['audio_mix']['bytes'])\n",
    "        audio_vocal, fs = torchaudio.load(sample['audio_vocal']['bytes'])\n",
    "        audio_mix = audio_mix.unsqueeze(1)\n",
    "        audio_vocal = audio_vocal.unsqueeze(1)\n",
    "        audio = torch.cat([audio_mix,audio_vocal],dim=1)\n",
    "        x[i_sample,:,:,:] = crop(audio)\n",
    "    return x[:,:,0,:], x[:,:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f69277e2-0d5e-4a90-819c-74d011664a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f6a6efe-42fa-47de-a1d0-72343cc9d94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,v = next(iter(dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
