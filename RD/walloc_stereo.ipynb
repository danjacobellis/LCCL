{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3be548-2f74-488e-a783-20097670ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://hf.co/danjacobellis/walloc/resolve/main/Stereo_Li_48c_J8_nf8_v1.0.2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ec9f03-99de-43f2-9276-3aebd3902c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name --format=csv,noheader | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange\n",
    "from IPython.display import Audio\n",
    "from torchvision.transforms import ToPILImage, PILToTensor\n",
    "from datasets import load_dataset, Image\n",
    "from walloc import walloc\n",
    "from spauq.core.metrics import spauq_eval\n",
    "import cdpam\n",
    "class Config: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389e035a-effe-4599-807b-96c213e5a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"Stereo_Li_48c_J8_nf8_v1.0.2.pth\",map_location=\"cpu\",weights_only=False)\n",
    "codec_config = checkpoint['config']\n",
    "codec = walloc.Codec1D(\n",
    "    channels = codec_config.channels,\n",
    "    J = codec_config.J,\n",
    "    Ne = codec_config.Ne,\n",
    "    Nd = codec_config.Nd,\n",
    "    latent_dim = codec_config.latent_dim,\n",
    "    latent_bits = codec_config.latent_bits,\n",
    "    lightweight_encode = codec_config.lightweight_encode,\n",
    "    post_filter = codec_config.post_filter\n",
    ")\n",
    "codec.load_state_dict(checkpoint['model_state_dict'])\n",
    "codec.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfc6e03e-ffcc-443f-be69-f6f75ba737e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/cdpam/cdpam.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(modfolder,map_location=\"cpu\")['state']\n"
     ]
    }
   ],
   "source": [
    "cdpam_loss = cdpam.CDPAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f156141c-9fed-4893-a143-02abbe802822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748d0f0a9063466c80da5e89dd407bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef8bada835b440296dbdd9962f485fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324c680139364b1f96a7388e3a41a1d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13c1119dd40c422aae2929e802d309fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MUSDB = load_dataset(\"danjacobellis/musdb18HQ\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c53fec1-ada4-42c6-a4c7-592046255e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def walloc_compress(sample):\n",
    "#     with torch.no_grad():\n",
    "#         img = sample['image']\n",
    "#         x = PILToTensor()(img).to(torch.float)\n",
    "#         x = (x/255 - 0.5).unsqueeze(0).to(device)\n",
    "#         H, W = x.size(2), x.size(3)\n",
    "#         x_padded = walloc.pad(x,p=16)\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "#         Y = codec.encoder(X)\n",
    "#         webp = walloc.latent_to_pil(Y.to(\"cpu\"),codec.latent_bits, 3)[0]\n",
    "#         buff = io.BytesIO()\n",
    "#         webp.save(buff, format='WEBP', lossless=True)\n",
    "#         webp_bytes = buff.getbuffer()\n",
    "#         encode_time = time.time() - t0\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "#         X_hat = codec.decoder(Y)\n",
    "#         x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "#         x_hat = codec.clamp(x_hat)\n",
    "#         decode_time = time.time() - t0\n",
    "        \n",
    "#         x_hat = walloc.crop(x_hat, (H,W))\n",
    "#         rec = ToPILImage()(x_hat[0] + 0.5)\n",
    "#         buff2 = io.BytesIO()\n",
    "#         rec.save(buff2, format='WEBP', lossless=True)\n",
    "#         rec_webp_bytes = buff2.getbuffer()\n",
    "\n",
    "#         bpp = 8*len(webp_bytes)/(H*W)\n",
    "#         PSNR = psnr(x+0.5,x_hat+0.5)\n",
    "#         MSSIM = multi_scale_ssim(x+0.5,x_hat+0.5)\n",
    "#         LPIPS_dB = -10*np.log10(lpips_loss(x.to(\"cuda\")+0.5, x_hat.to(\"cuda\")+0.5).item())\n",
    "#         DISTS_dB = -10*np.log10(dists_loss(x.to(\"cuda\")+0.5, x_hat.to(\"cuda\")+0.5).item())        \n",
    "        \n",
    "#     return {\n",
    "#         'recovered': rec_webp_bytes,\n",
    "#         'compressed': webp_bytes,\n",
    "#         'encode_time': encode_time,\n",
    "#         'decode_time': decode_time,\n",
    "#         'bpp': bpp,\n",
    "#         'PSNR': PSNR,\n",
    "#         'MSSIM': MSSIM,\n",
    "#         'LPIPS_dB': LPIPS_dB,\n",
    "#         'DISTS_dB': DISTS_dB,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a4d392-f9b7-4d92-b656-a33ecffdf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda\"\n",
    "# codec = codec.to(device)\n",
    "# gpu = LSDIR.map(walloc_compress)\n",
    "# gpu = gpu.cast_column('recovered',Image())\n",
    "# gpu = gpu.cast_column('compressed',Image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ed7b5ec-3124-470f-86b4-359c2389e9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def walloc_compress_cpu(sample):\n",
    "#     with torch.no_grad():\n",
    "#         img = sample['image']\n",
    "#         x = PILToTensor()(img).to(torch.float)\n",
    "#         x = (x/255 - 0.5).unsqueeze(0).to(device)\n",
    "#         H, W = x.size(2), x.size(3)\n",
    "#         x_padded = walloc.pad(x,p=8)\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "#         Y = codec.encoder(X)\n",
    "#         webp = walloc.latent_to_pil(Y.to(\"cpu\"),codec.latent_bits, 3)[0]\n",
    "#         buff = io.BytesIO()\n",
    "#         webp.save(buff, format='WEBP', lossless=True)\n",
    "#         webp_bytes = buff.getbuffer()\n",
    "#         encode_time = time.time() - t0\n",
    "\n",
    "#         t0 = time.time()\n",
    "#         Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "#         X_hat = codec.decoder(Y)\n",
    "#         x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "#         x_hat = codec.clamp(x_hat)\n",
    "#         decode_time = time.time() - t0\n",
    "                \n",
    "#     return {\n",
    "#         'cpu_encode_time': encode_time,\n",
    "#         'cpu_decode_time': decode_time,\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5ddb0a9-70c7-46c4-b8bd-83aa7eb73268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cpu\"\n",
    "# codec = codec.to(device)\n",
    "# cpu = LSDIR.map(walloc_compress_cpu)\n",
    "# combined = gpu.add_column('cpu_encode_time',cpu['cpu_encode_time'])\n",
    "# combined = combined.add_column('cpu_decode_time',cpu['cpu_decode_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77d2fd0-f5b5-45b8-a386-65db975d376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = [\n",
    "#      'encode_time',\n",
    "#      'decode_time',\n",
    "#      'bpp',\n",
    "#      'PSNR',\n",
    "#      'MSSIM',\n",
    "#      'LPIPS_dB',\n",
    "#      'DISTS_dB', \n",
    "#      'cpu_encode_time',\n",
    "#      'cpu_decode_time',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1baaf00-9378-40ab-95d0-ef8f3e1d9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for metric in metrics:\n",
    "#     μ = np.mean(combined[metric])\n",
    "#     print(f\"{metric}: {μ}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa3f54-5f05-4607-b805-14a4e3fbc2c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4253a3a3-40d1-49fd-8f04-190dc481423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = 1048064\n",
    "# sample = MUSDB[5]\n",
    "# x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "# x = x[:,:L]\n",
    "# codec = codec.to(\"cuda\")\n",
    "# x = x.to(\"cuda\").unsqueeze(0)\n",
    "# with torch.no_grad():\n",
    "#     X = codec.wavelet_analysis(x,codec.J)\n",
    "#     Y = codec.encoder(X)\n",
    "#     Z = codec.decoder(Y)\n",
    "#     z = codec.wavelet_synthesis(Z,codec.J)\n",
    "#     z = codec.post(z)\n",
    "# x = x.to(\"cpu\")[0]\n",
    "# z = z.to(\"cpu\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c80f71af-4b52-4afc-8ad6-d03af3828982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(x.numpy(),rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f56389a-c617-4510-8d0b-d08b4e96ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio(z.numpy(),rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28e614a2-25ec-413a-b664-cb5a74a0e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start, end = 56500, 57000\n",
    "# plt.figure(figsize=(8, 4), dpi=180)\n",
    "# plt.plot(x[0, start:end], alpha=0.5, c='b', label='Ch.1 (Uncompressed)')\n",
    "# plt.plot(z[0, start:end], alpha=0.5, c='g', label='Ch.1 (WaLLoC)')\n",
    "# plt.plot(x[1, start:end], alpha=0.5, c='r', label='Ch.2 (Uncompressed)')\n",
    "# plt.plot(z[1, start:end], alpha=0.5, c='purple', label='Ch.2 (WaLLoC)')\n",
    "\n",
    "# plt.ylim([-1,0.6])\n",
    "# plt.legend(loc='lower center')\n",
    "# plt.box(False)\n",
    "# plt.xticks([])\n",
    "# plt.yticks([])\n",
    "# # plt.savefig(\"test.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19a63a7e-c0a6-4bfe-846e-cd60a53a41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B,C,L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        audio = torch.nn.functional.pad(audio, (0, padding_size), mode='constant', value=0)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de12cf92-b07d-45b5-9612-c2fff761e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "codec = codec.to(device)\n",
    "sample = MUSDB[5]\n",
    "with torch.no_grad():\n",
    "    x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "    L = x.shape[-1]\n",
    "    x_padded = pad(x.unsqueeze(0), 2**16).to(device)\n",
    "    t0 = time.time()\n",
    "    X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "    Y = codec.encoder(X)\n",
    "    ℓ = Y.shape[-1]\n",
    "    Y = pad(Y,256)\n",
    "    Y = rearrange(Y, 'b c (w h) -> b c w h', h=256).to(\"cpu\")\n",
    "    webp = walloc.latent_to_pil(Y,codec.latent_bits,3)[0]\n",
    "    buff = io.BytesIO()\n",
    "    webp.save(buff, format='WEBP', lossless=True)\n",
    "    webp_bytes = buff.getbuffer()\n",
    "    encode_time = time.time() - t0\n",
    "\n",
    "    t0 = time.time()\n",
    "    Y = walloc.pil_to_latent([PIL.Image.open(buff)], codec.latent_dim, codec.latent_bits, 3).to(device)\n",
    "    X_hat = codec.decoder(rearrange(Y.to(device), 'b c h w -> b c (h w)')[:,:,:ℓ])\n",
    "    x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "    x_hat = codec.post(x_hat)\n",
    "    x_hat = x_hat[0,:,:L].clamp(-1., 1.)\n",
    "    decode_time = time.time() - t0\n",
    "\n",
    "    bps = 8*len(webp_bytes)/(x.numel())\n",
    "    PSNR = 20*np.log10(2) - 10*np.log10(torch.nn.functional.mse_loss(x,x_hat.to(\"cpu\")))\n",
    "    SDR = spauq_eval(x,x_hat.to(\"cpu\"),fs=fs)\n",
    "    SSDR = SDR['SSR']\n",
    "    SRDR = SDR['SRR']\n",
    "    cdpam = cdpam_loss.forward(x.to(device),x_hat).mean().item()\n",
    "    \n",
    "# return {\n",
    "#     'compressed': webp_bytes,\n",
    "#     'encode_time': encode_time,\n",
    "#     'decode_time': decode_time,\n",
    "#     'bps': bps,\n",
    "#     'PSNR': PSNR,\n",
    "#     'SSDR': SSDR\n",
    "#     'SRDR': SRDR\n",
    "#     'CDPAM': cdpam\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b2e6847-0c92-427e-8d08-2f151ead2431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.444941745567345"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73fefeb5-caca-45fd-88f6-ac2ed1cc9344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33.7881)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb9a7dc1-86fe-4293-bfa5-fc7e336604ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.305854846064648"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ccae76d-0def-4cf3-970c-75dfdaf3dba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.542482940408304"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c801792-e413-446c-a127-4afbe38460eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.069673755746024"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-10*np.log10(cdpam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
