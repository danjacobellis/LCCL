{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45ef59-817d-424a-a9cf-53304f704e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://hf.co/danjacobellis/walloc/resolve/main/Stereo_Li_192c_J8_nf8_v1.0.2.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5369da-f14e-4091-967e-cedc7a7ccaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -U git+https://github.com/facebookresearch/demucs#egg=demucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "448d5158-5bfa-4f21-8651-f9e0234b8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import tempfile\n",
    "from demucs.separate import Separator\n",
    "from IPython.display import Audio\n",
    "from datasets import load_dataset\n",
    "from walloc import walloc\n",
    "from spauq.core.metrics import spauq_eval\n",
    "from fastprogress.fastprogress import progress_bar\n",
    "class Config: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518cefc3-ab2a-4b08-aeae-d5e449e3bba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:134: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "checkpoint = torch.load(\"Stereo_Li_192c_J8_nf8_v1.0.2.pth\",map_location=\"cpu\",weights_only=False)\n",
    "codec_config = checkpoint['config']\n",
    "codec = walloc.Codec1D(\n",
    "    channels = codec_config.channels,\n",
    "    J = codec_config.J,\n",
    "    Ne = codec_config.Ne,\n",
    "    Nd = codec_config.Nd,\n",
    "    latent_dim = codec_config.latent_dim,\n",
    "    latent_bits = codec_config.latent_bits,\n",
    "    lightweight_encode = codec_config.lightweight_encode,\n",
    "    post_filter = codec_config.post_filter\n",
    ").to(device)\n",
    "codec.load_state_dict(checkpoint['model_state_dict'])\n",
    "codec.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068d2dae-0633-4689-9a26-d1df46532b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caeed21ec3f74c2ea5838a5f4726d712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad2aea518e54d0cb8598b035a4ab881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef43dee6319848a39433b8088a9879b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef25f98cd4fb4435b4e8e2ac906dde8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MUSDB = load_dataset(\"danjacobellis/musdb18HQ\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "263cece1-6297-43e2-93a8-b3209723c080",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator = Separator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "927b458d-dd37-4fa5-8650-8b665033e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B,C,L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        audio = torch.nn.functional.pad(audio, (0, padding_size), mode='constant', value=0)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af12eefe-0925-4458-9577-760f3fa10d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='50' class='' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [50/50 16:36&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/spauq/core/preprocessing.py:325: UserWarning: No forgive_mode specified, defaulting to `none`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_duration=44100*180\n",
    "SSDR = []\n",
    "SRDR = []\n",
    "with torch.no_grad():\n",
    "    for i_sample in progress_bar(range(0, len(MUSDB), 5)):\n",
    "        SSDR.append([])\n",
    "        SRDR.append([])\n",
    "        y = []\n",
    "        for i_instr in range(5):\n",
    "            sample = MUSDB[i_sample+i_instr]\n",
    "            instr = sample['instrument']\n",
    "            x, fs = torchaudio.load(sample['audio']['bytes'])\n",
    "            x = x[:,:max_duration]\n",
    "            L = x.shape[-1]\n",
    "            x_padded = pad(x.unsqueeze(0), 2**16).to(device)\n",
    "\n",
    "            X = codec.wavelet_analysis(x_padded,codec.J)\n",
    "            Y = codec.encoder(X)\n",
    "            X_hat = codec.decoder(Y)\n",
    "            x_hat = codec.wavelet_synthesis(X_hat,codec.J)\n",
    "            x_hat = codec.post(x_hat)\n",
    "\n",
    "            if i_instr == 0:\n",
    "                pred = separator.separate_tensor(x_hat[0])\n",
    "            else:\n",
    "                SDR = spauq_eval(\n",
    "                    reference=x_padded[0].to(\"cpu\"),\n",
    "                    estimate=pred[1][instr].to(\"cpu\"),\n",
    "                    fs = fs\n",
    "                )\n",
    "                SSDR[-1].append(SDR['SSR'])\n",
    "                SRDR[-1].append(SDR['SRR'])\n",
    "SSDR = torch.tensor(SSDR)\n",
    "SRDR = torch.tensor(SRDR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "256997e0-c8a7-4dfc-acfe-e54e0f7612f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.0237, 17.3669, 15.4579, 11.6876], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSDR.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b13d21f-3697-4219-b3cf-04651c43220e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14.6340, dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSDR.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05e9618f-6e25-47a1-9c04-765c5a3729d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.3192,  7.3617,  0.3864, -1.6658], dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRDR.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85c98f2b-8c52-4a0e-81e3-56b6ea9d0be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6004, dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRDR.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
